{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434a9a23-3568-4a91-b023-905447c9e885",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - Introduction\n",
    "\n",
    "The **Naive Bayes Classifier** is a simple yet powerful algorithm based on **Bayes' Theorem**. It is particularly useful for classification tasks where the features are assumed to be independent. This \"naive\" assumption simplifies the calculations, making it efficient and easy to implement. Despite this assumption, it often performs surprisingly well in many real-world applications such as text classification and medical diagnoses.\n",
    "\n",
    "### Code Overview:\n",
    "\n",
    "In the provided Python implementation, we train the Naive Bayes classifier to predict whether a person will have a fever based on two symptoms: COVID and Flu. The model calculates the **prior probabilities** of having a fever and the **conditional probabilities** of each feature (COVID and Flu). It then predicts the outcome (Fever/No Fever) for different combinations of symptoms.\n",
    "\n",
    "- **Training Data**: The data includes binary values for COVID and Flu symptoms (1 for Yes, 0 for No) and corresponding labels for whether the person has a fever.\n",
    "- **Prediction**: The trained classifier is tested on all possible combinations of symptoms to predict whether the person is likely to have a fever.\n",
    "\n",
    "This is a simple demonstration of how Naive Bayes can be applied to a classification problem using binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01ef9f-20d1-40c5-adb1-75e6cb22fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.priors = {}\n",
    "        self.conditionals = {}\n",
    "        self.labels = []\n",
    "\n",
    "    def train(self, data, labels):\n",
    "        \"\"\"\n",
    "        Train the classifier by calculating prior and conditional probabilities.\n",
    "        :param data: List of feature tuples\n",
    "        :param labels: List of corresponding labels\n",
    "        \"\"\"\n",
    "        self.labels = list(set(labels))  # Unique labels (Fever/No Fever)\n",
    "        label_count = {label: 0 for label in self.labels}  # Count occurrences of each label\n",
    "        feature_counts = {label: {} for label in self.labels}  # Count feature values per label\n",
    "        \n",
    "        for i, label in enumerate(labels):\n",
    "            label_count[label] += 1\n",
    "            for j, feature in enumerate(data[i]):\n",
    "                if j not in feature_counts[label]:\n",
    "                    feature_counts[label][j] = {}\n",
    "                if feature not in feature_counts[label][j]:\n",
    "                    feature_counts[label][j][feature] = 0\n",
    "                feature_counts[label][j][feature] += 1\n",
    "\n",
    "        total_samples = len(labels)\n",
    "        # Calculate priors (P(label))\n",
    "        self.priors = {label: label_count[label] / total_samples for label in self.labels}\n",
    "        \n",
    "        # Calculate conditional probabilities (P(feature|label))\n",
    "        self.conditionals = {label: {} for label in self.labels}\n",
    "        for label in self.labels:\n",
    "            for feature_index in feature_counts[label]:\n",
    "                self.conditionals[label][feature_index] = {\n",
    "                    feature: (count / label_count[label]) for feature, count in feature_counts[label][feature_index].items()\n",
    "                }\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Predict the label based on feature values.\n",
    "        :param features: List of feature values\n",
    "        :return: Predicted label (1 for Fever, 0 for No Fever)\n",
    "        \"\"\"\n",
    "        probabilities = {}\n",
    "        for label in self.labels:\n",
    "            prob = self.priors[label]\n",
    "            for j, feature in enumerate(features):\n",
    "                if feature in self.conditionals[label].get(j, {}):\n",
    "                    prob *= self.conditionals[label][j][feature]\n",
    "                else:\n",
    "                    prob *= 0\n",
    "            probabilities[label] = prob\n",
    "        \n",
    "        return max(probabilities, key=probabilities.get)  # Return label with highest probability\n",
    "\n",
    "# Training data: (COVID, Flu) where 1 = Yes, 0 = No\n",
    "data = [\n",
    "    (1, 1), (1, 0), (0, 1), (0, 0), \n",
    "    (1, 1), (0, 1), (0, 0), (1, 0), \n",
    "    (0, 0), (1, 1)\n",
    "]\n",
    "\n",
    "# Labels: 1 = Fever, 0 = No Fever\n",
    "labels = [1, 1, 1, 0, 1, 1, 0, 1, 0, 1]\n",
    "\n",
    "# Train the classifier\n",
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(data, labels)\n",
    "\n",
    "# Test cases: all combinations of COVID and Flu\n",
    "test_cases = [\n",
    "    (1, 1),  # Both COVID and Flu\n",
    "    (1, 0),  # COVID but not Flu\n",
    "    (0, 1),  # Flu but not COVID\n",
    "    (0, 0)   # Neither COVID nor Flu\n",
    "]\n",
    "\n",
    "# Print predictions\n",
    "for test in test_cases:\n",
    "    prediction = classifier.predict(test)\n",
    "    result = \"Fever\" if prediction == 1 else \"No Fever\"\n",
    "    print(f\"Prediction for COVID = {test[0]}, Flu = {test[1]}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
